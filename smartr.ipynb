{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm using yfinance package to download the stock data from yahoo finance. Then I will try predicting the prices for each stock. My goal is to make a prediction on the expected value and variance of the price based on the previous values. Then I'll try to compute the experimental covarience between different stocks and input them to an optimization problem designed to reduce the mixed variance while maximizing the expected output. This is based on the mean-volatility predicate in financial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft = yf.Ticker(\"MSFT\")\n",
    "temp_hist = msft.history(period=\"9y\", interval=\"1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running for first time, you need to downloaded the stock symbols or \"tickers\". This is in done by setting parameter  \"get_tickers\".<br> Currently I'm downloading the daily data for 9years. If you already have downloaded some part of the data you can download the rest and append them to each other. Later I hope to automatize this section, since my goal is to run this script once weekly or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tickers = False \n",
    "get_histories = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_tickers:\n",
    "    !curl -o /Users/abnousa/software/smartop/nasdaqtraded_companylist.txt ftp://ftp.nasdaqtrader.com/symboldirectory/nasdaqtraded.txt\n",
    "    symbols = pd.read_csv(\"/Users/abnousa/software/smartop/nasdaqtraded_companylist.txt\", sep = \"|\")\n",
    "    symbols = symbols.iloc[0:(symbols.shape[0] - 1),:] #last row is time\n",
    "    tickers = {}\n",
    "    failed = []\n",
    "    for i in symbols.index:\n",
    "        sym = symbols.iloc[i]['Symbol']\n",
    "        ticker = yf.Ticker(sym)\n",
    "        try:\n",
    "            check = ticker.calendar\n",
    "        except Exception as e:\n",
    "            print(' '.join([\"disregarding\", sym, type(e).__name__]))\n",
    "            failed.append(sym)\n",
    "            continue\n",
    "        print(' '.join([sym, 'added']))\n",
    "        name = symbols.iloc[i]['Security Name']\n",
    "        tickers[sym] = {'name': name, 'ticker': ticker}\n",
    "    sym_data = {'tickers':tickers, 'failed':failed}\n",
    "    with open('sym_data.pkl', 'wb') as symfile:\n",
    "        pickle.dump(sym_data, symfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sym_data.pkl', 'rb') as symfile:\n",
    "    sym_data = pickle.load(symfile)\n",
    "    tickers, failed = sym_data['tickers'], sym_data['failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_histories:\n",
    "    msft = yf.Ticker(\"MSFT\")\n",
    "    temp_hist = msft.history(period=\"9y\", interval=\"1d\")\n",
    "    d = pd.DataFrame(data = 0, columns = list(tickers.keys()), index = temp_hist.index)\n",
    "    for i in d.columns:\n",
    "        print(i)\n",
    "        hist = tickers[i]['ticker'].history(start = list(temp_hist.index)[0], end = list(temp_hist.index)[-1], interval = \"1d\")['Open']\n",
    "        d[i] = hist\n",
    "    with open(\"daily_history_9y.pkl\", 'wb') as histfile:\n",
    "        pickle.dump(d, histfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"daily_history_9y.pkl\", 'rb') as infile:\n",
    "    d = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the stock data have a lot of missing points over the past 9 years. This might be because they were founded later or had their IPO sometime during this time-period. Below I take a look at the number of stocks with various numbers of missing points and filter the data to the ones with less than 20 NA's. I will impute the missing points by \"backward filling\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4166.,   28.,   26.,   48.,   21.,   23.,   20.,   10.,   23.,\n",
       "          24.,   22.,    8.,   56.,   17.,   46.,   21.,   14.,   23.,\n",
       "          17.,   24.,   34.,   11.,   16.,   27.,   21.,   30.,   29.,\n",
       "          31.,   28.,   23.,   38.,   60.,   27.,   23.,   46.,   28.,\n",
       "          41.,   41.,   53.,   40.,   24.,   44.,   44.,   34.,   31.,\n",
       "          34.,   32.,   25.,   35.,   36.,   58.,   28.,   32.,   36.,\n",
       "          38.,   29.,   16.,   20.,   25.,   36.,   39.,   28.,   25.,\n",
       "          46.,   39.,   26.,   34.,   35.,   21.,   27.,   38.,   37.,\n",
       "          62.,   28.,   30.,   57.,   89.,   50.,   45.,   40.,   48.,\n",
       "          37.,   45.,   46.,   56.,   45.,   71.,   46.,   35.,   33.,\n",
       "          25.,   66.,   59.,   44.,   38.,   38.,   20.,   57.,   47.,\n",
       "          38.]),\n",
       " array([   0.  ,   22.64,   45.28,   67.92,   90.56,  113.2 ,  135.84,\n",
       "         158.48,  181.12,  203.76,  226.4 ,  249.04,  271.68,  294.32,\n",
       "         316.96,  339.6 ,  362.24,  384.88,  407.52,  430.16,  452.8 ,\n",
       "         475.44,  498.08,  520.72,  543.36,  566.  ,  588.64,  611.28,\n",
       "         633.92,  656.56,  679.2 ,  701.84,  724.48,  747.12,  769.76,\n",
       "         792.4 ,  815.04,  837.68,  860.32,  882.96,  905.6 ,  928.24,\n",
       "         950.88,  973.52,  996.16, 1018.8 , 1041.44, 1064.08, 1086.72,\n",
       "        1109.36, 1132.  , 1154.64, 1177.28, 1199.92, 1222.56, 1245.2 ,\n",
       "        1267.84, 1290.48, 1313.12, 1335.76, 1358.4 , 1381.04, 1403.68,\n",
       "        1426.32, 1448.96, 1471.6 , 1494.24, 1516.88, 1539.52, 1562.16,\n",
       "        1584.8 , 1607.44, 1630.08, 1652.72, 1675.36, 1698.  , 1720.64,\n",
       "        1743.28, 1765.92, 1788.56, 1811.2 , 1833.84, 1856.48, 1879.12,\n",
       "        1901.76, 1924.4 , 1947.04, 1969.68, 1992.32, 2014.96, 2037.6 ,\n",
       "        2060.24, 2082.88, 2105.52, 2128.16, 2150.8 , 2173.44, 2196.08,\n",
       "        2218.72, 2241.36, 2264.  ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(d.isna().sum(), bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2264, 4165)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = d.iloc[:, list(np.where(d.isna().sum() < 20)[0])]\n",
    "d = d.fillna(method = \"bfill\")\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, now we have the data and for each stock we can take a look at their trend. Change the *ticker_name* below and have a look at the plot. I'm plotting the Microsoft stock prices from some day in December 2012 up to December 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13451b4a8>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ticker_name = \"MSFT\"\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(d[ticker_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we have the data, now it's time to model them. Here we have some choices to make. I have listed a few of them here and also explained my approach:\n",
    "- First question is whether we want to model the problem as univariate or multivariate prediction. i.e. looking at each stock separately or try getting help from other stocks' data in forecasting of the price.\n",
    " *  My initial goal was to build a multivariate model. I have over 4000 stock tickers that I want to analyze. My [non-financially-trained] thinking was that these stocks are correlated one-way or another and we can use the trend in one stock to help prediction in other stock as well. This proved to be a difficult thing to do. i.e. I had worse performance when training multivariate model as opposed to univariate. I still have a filling that multivariate is the way to go*. But since I rather have shallower networks that won't take long training, I will be approahcing the problem as univariate, meaning I will loop over each company, train a model for that stock based only on that stock's data and make prediction, then move to the next company. *Another approach that I have a strong feeling about is to first cluster the companies for example based on the type of business and try multivariate forecasting for each cluster. For example we can try multivariate forecasting for fintech companies, then for construction companies, then for biotech or pharmaceutical companies. This method assumes that macroeconomic trends affect a whole set of businesses and we can better capture the variations in prices of these businesses if we look at them as a whole. I yet have to try this method.*\n",
    "- Another choice -a rather technical one- is about data normalization. As a rule of thumb we know that we generally need to perform some type of data normalization. Well, here is a table I compiled based on a few small experiments. In all these experiments I have tried a shallow network with 3 to 4 layers and each layer with 128 to 512 units of the specified type. Interestingly, as you can see in this table many of the methods result in a prediction closer to the mean of the training data. Of course, **this can be most of all a result of the loss function**, as well as other factors, including network architecture, and the normalization method.\n",
    "\n",
    "| Architecture | Normalization | Loss | Output|  \n",
    "|-|-|-|-|  \n",
    "| SimpleRNN-based | None  |  mae, mse, or huber | close to mean with small variance |  \n",
    "| SimpleRNN-based | 0-1 scaling  |  mae, mse, or huber | close to mean with small variance |  \n",
    "| LSTM-based | None  |  mae, mse, or huber | close to mean with small variance |  \n",
    "| LSTM-based | 0-1 scaling  |  mae, mse, or huber | better than mean! |  \n",
    "| GRU-based | None  |  mae, mse, or huber | close to mean with small variance |  \n",
    "| GRU-based | 0-1 scaling  |  mae, mse, or huber | better than mean! |  \n",
    "\n",
    "* Loss Function: MSE gives higher value to outliers, whereas MAE gives equal importance to all data points. Huber works somewhere in between the MSE and MAE, with quadratic penalty for smaller losses and linear penalty for larger losses. I don't like how MSE performs on this data, MAE and Huber are better options IMHO, but feel free to change it if you'd like.\n",
    "\n",
    "*A NOTE ON DATA NORMALIZATION:* A silly mistake I made here and took me hours to realize and fix: We are performing a simple scaling of data to 0-1. I was excited to learn about the *Lambda* layers in keras. And I was trying to do the scaling using these layers by pre-computing the maximum of each column in the training data (in multivariate setting, or the maximum of \"the column\" in the univariate setting) and passing it on to the lambda layer which would run the scaling code below by dividing all entries of a column to the maximum of that column (computed from training data). Then performing the reverse on the output of the model. On the other hand, since I was performing a data scaling to 0-1, I automatically set my last layer to have a 'tanh' activation, followed by (x+1)/2 in the scaling lambda layer. Sounds fair, right?! NO - because the scaling factors are computed on the training data, and the post-modified tanh layer output is in 0-1 range, multiplying it by the normalization factor can be at most as big as the normalization factor, aka the maximum number in each column in the training data. Surprise, our prices are not limited to that range, and I certainly hope the stock will have an upward trend, exceeding the maximum in the previous values. Simple solution: do not use tanh or sigmoid or softmax on your last layer; let it roam freely! Use linear, or relu maybe? (another option is to use the maximum in the entire column rather than training data, but still that limits our output to a certain number if your output layer has for exampe tanh activation). After all, it seems like exponential and **elu** activation on the output layer (prior to scaling back) gives the best performance in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is copied exactly from the deeplearning.ai course on time-series analysis on coursera!\n",
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "    dataset = dataset.shuffle(shuffle_buffer).map(lambda window: (window[:-1], window[-1]))\n",
    "    dataset = dataset.batch(batch_size).prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.591899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.918005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.940000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.517500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>84.940000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 A\n",
       "count  2264.000000\n",
       "mean     44.591899\n",
       "std      16.918005\n",
       "min      18.940000\n",
       "25%      30.517500\n",
       "50%      39.035000\n",
       "75%      61.800000\n",
       "max      84.940000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d = d.iloc[:, :1]#:int(d.shape[1]/2)]\n",
    "d = d.loc[:,['A']]\n",
    "d.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.reset_index(drop = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456, 3)\n",
      "         Date      A weekday\n",
      "5  2010-12-31  27.18  Friday\n",
      "10 2011-01-07  27.24  Friday\n",
      "15 2011-01-14  28.07  Friday\n",
      "19 2011-01-21  27.88  Friday\n",
      "24 2011-01-28  27.88  Friday\n"
     ]
    }
   ],
   "source": [
    "d['weekday'] = d['Date'].dt.day_name()\n",
    "d = d[d['weekday'] == \"Friday\"]\n",
    "print(d.shape)\n",
    "print(d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>456.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>44.713026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.060799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>62.732500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>84.940000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A\n",
       "count  456.000000\n",
       "mean    44.713026\n",
       "std     17.060799\n",
       "min     20.330000\n",
       "25%     30.500000\n",
       "50%     39.090000\n",
       "75%     62.732500\n",
       "max     84.940000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = d.loc[:,['A']]\n",
    "d.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30\n",
    "batch_size = 32\n",
    "shuffle_buffer = 100000\n",
    "training_points = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = d / train_d.max(axis = 0)\n",
    "train_d = d.iloc[:training_points, :]\n",
    "valid_d = d.iloc[-training_points:, :]\n",
    "train_df = windowed_dataset(train_d.to_numpy(), window_size, batch_size, shuffle_buffer)\n",
    "normalization_factors = train_d.max()\n",
    "valid_df = windowed_dataset(valid_d.to_numpy(), window_size, batch_size, shuffle_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>66.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>66.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>66.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>67.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>67.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A\n",
       "1723  66.61\n",
       "1728  66.89\n",
       "1733  66.16\n",
       "1738  67.32\n",
       "1742  67.62"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_d.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_normalize(x, factors = None, denorm = False):\n",
    "    if factors is None:\n",
    "        factors = tf.reduce_max(x, axis = 0, keepdims = False)\n",
    "        #tf.print(factors)\n",
    "        tf.print(\"pre mod shape of x\")\n",
    "        tf.print(tf.shape(x))\n",
    "        tf.print(\"shape of factors\")\n",
    "        tf.print(tf.shape(factors))\n",
    "    if denorm:\n",
    "        #x += 1\n",
    "        factors = 1. / factors\n",
    "    x /= factors\n",
    "    #tf.print(\"post mod shape of x\")\n",
    "    #tf.print(tf.shape(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (<tensorflow.python.keras.layers.core.Dense object at 0x137d42898>) with an unsupported type (<class 'tensorflow.python.keras.layers.core.Dense'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ConcatV2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m         name, _ctx._post_execution_callbacks, values, axis)\n\u001b[0m\u001b[1;32m   1237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: This function does not handle the case of the path where all inputs are not already EagerTensors.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-9dce7850631c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0msigmoid_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mrelu_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msigmoid_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelu_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0minner_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1429\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[1;32m   1430\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1239\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m         return concat_v2_eager_fallback(\n\u001b[0;32m-> 1241\u001b[0;31m             values, axis, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   1242\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2_eager_fallback\u001b[0;34m(values, axis, name, ctx)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \"'concat_v2' Op, not %r.\" % values)\n\u001b[1;32m   1283\u001b[0m   \u001b[0m_attr_N\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m   \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m   \u001b[0m_attr_Tidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs_to_matching_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36margs_to_matching_eager\u001b[0;34m(l, ctx, default_dtype)\u001b[0m\n\u001b[1;32m    255\u001b[0m       ret.append(\n\u001b[1;32m    256\u001b[0m           internal_convert_to_tensor(\n\u001b[0;32m--> 257\u001b[0;31m               t, dtype, preferred_dtype=default_dtype, ctx=ctx))\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    284\u001b[0m                                          as_ref=False):\n\u001b[1;32m    285\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (<tensorflow.python.keras.layers.core.Dense object at 0x137d42898>) with an unsupported type (<class 'tensorflow.python.keras.layers.core.Dense'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "output_size = train_d.shape[1]\n",
    "#output_size = 1\n",
    "print(output_size)\n",
    "inner_layers = tf.keras.models.Sequential([\n",
    "  #tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1), input_shape=[None]), #if the input is one stock\n",
    "  tf.keras.layers.Lambda(layer_normalize, arguments={'factors': normalization_factors, 'denorm' : False}),\n",
    "  #tf.keras.layers.Conv1D(128, kernel_size = 3, input_shape = (batch_size, window_size, None)),\n",
    "  #tf.keras.layers.AveragePooling1D(),\n",
    "  #tf.keras.layers.Conv1D(256, kernel_size = 3),\n",
    "  #tf.keras.layers.AveragePooling1D(),\n",
    "  #tf.keras.layers.Conv1D(256, kernel_size = 1),\n",
    "  #tf.keras.layers.AveragePooling1D(),\n",
    "  #tf.keras.layers.Conv1D(256, kernel_size = 1, activation = 'relu'),\n",
    "  #tf.keras.layers.AveragePooling1D(),\n",
    "  #tf.keras.layers.GRU(512, return_sequences=True),\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  #tf.keras.layers.GRU(256, return_sequences=True),\n",
    "  #tf.keras.layers.GRU(256, return_sequences=True),\n",
    "  #tf.keras.layers.GRU(256, return_sequences=True),\n",
    "  #tf.keras.layers.GRU(256),\n",
    "  #tf.keras.layers.SimpleRNN(128, return_sequences=True),\n",
    "  #tf.keras.layers.SimpleRNN(256, return_sequences=True),\n",
    "  #tf.keras.layers.SimpleRNN(512, return_sequences=True),\n",
    "  #tf.keras.layers.SimpleRNN(256, return_sequences=True),\n",
    "  #tf.keras.layers.SimpleRNN(128),\n",
    "  tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "  tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "  tf.keras.layers.LSTM(128),\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  #tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  #tf.keras.layers.LSTM(256, return_sequences=True, activation = 'relu'),\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  #tf.keras.layers.LSTM(256, return_sequences=True, activation = 'relu'),\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  #tf.keras.layers.LSTM(256, return_sequences=True, activation = 'relu'),\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  #tf.keras.layers.LSTM(256, return_sequences=True, activation = 'relu'),\n",
    "  #tf.keras.layers.LSTM(256, return_sequences=True, activation = 'relu'),\n",
    "  #tf.keras.layers.LSTM(256, return_sequences=True, activation = 'relu'),\n",
    "  #tf.keras.layers.Dropout(0.5),\n",
    "  #tf.keras.layers.LSTM(256, return_sequences=True, activation = 'relu'),\n",
    "  #tf.keras.layers.LSTM(256, return_sequences=True, activation = 'relu'),\n",
    "  #tf.keras.layers.LSTM(256, activation = 'tanh', return_sequences=True),\n",
    "  #tf.keras.layers.LSTM(128),\n",
    "  #tf.keras.layers.SimpleRNN(64, return_sequences = True),\n",
    "  #tf.keras.layers.SimpleRNN(128, return_sequences = True),\n",
    "  #tf.keras.layers.SimpleRNN(256),\n",
    "#  tf.keras.layers.Dense(output_size, activation = 'elu'),\n",
    "  #tf.keras.layers.Lambda(lambda x: x + 1),\n",
    "#  tf.keras.layers.Lambda(layer_normalize, arguments={'factors': normalization_factors, 'denorm' : True})\n",
    "])\n",
    "\n",
    "sigmoid_out = tf.keras.layers.Dense(units=1, activation=tf.nn.sigmoid)\n",
    "relu_out = tf.keras.layers.Dense(units=1, activation=tf.nn.relu)\n",
    "out = tf.concat([sigmoid_out, relu_out], axis=1)\n",
    "inner_layers.add(out)\n",
    "\n",
    "denorm_layer = tf.keras.layers.Lambda(layer_normalize, arguments={'factors': normalization_factors, 'denorm' : True})\n",
    "\n",
    "inner_layers.add(denorm_layer)\n",
    "model = inner_layers\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-2 * 10**(epoch / 20))\n",
    "#optimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n",
    "#optimizer = tf.keras.optimizers.SGD(lr=1e-7, momentum=0.9)\n",
    "#optimizer = tf.keras.optimizers.SGD(lr=1e-10, momentum = 0.9, clipnorm = 2)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "#optimizer = tf.keras.optimizers.RMSprop()\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              #loss = 'mse',\n",
    "              optimizer=optimizer,\n",
    "              #optimizer = 'Adam',\n",
    "              metrics = ['mae']\n",
    "             )\n",
    "#model.build(input_shape = (batch_size, window_size, None))\n",
    "#model.summary()\n",
    "#history = model.fit(df, epochs=2, callbacks = [lr_schedule])\n",
    "history = model.fit(train_df, epochs=10, validation_data = valid_df)#, callbacks = [lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>350.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.926943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.391520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>67.620000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A\n",
       "count  350.000000\n",
       "mean    36.926943\n",
       "std     10.391520\n",
       "min     20.330000\n",
       "25%     28.770000\n",
       "50%     36.630000\n",
       "75%     40.460000\n",
       "max     67.620000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.to_numpy()[50:55, :8]\n",
    "train_d.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456, 1)\n",
      "(320, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.138153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.294842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.992464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.061047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.789833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.328719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>68.559135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  320.000000\n",
       "mean    37.138153\n",
       "std     10.294842\n",
       "min     22.992464\n",
       "25%     28.061047\n",
       "50%     37.789833\n",
       "75%     40.328719\n",
       "max     68.559135"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#p = model.predict(np.array(d['MSFT']).reshape((len(d['MSFT']), 1)))\n",
    "p = model.predict(train_df)\n",
    "#p = p.reshape((1480, 4165))\n",
    "print(d.shape)\n",
    "print(p.shape)\n",
    "p = pd.DataFrame(p)\n",
    "p2 = p #* d.max(axis = 0).reset_index(drop = True)\n",
    "p2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(456, 1)\n",
      "(320, 1)\n",
      "                0\n",
      "count  320.000000\n",
      "mean    53.647156\n",
      "std     17.604563\n",
      "min     29.650517\n",
      "25%     38.942946\n",
      "50%     45.921932\n",
      "75%     72.340284\n",
      "max     86.852776\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(valid_df)\n",
    "#p = p.reshape((1480, 4165))\n",
    "print(d.shape)\n",
    "print(p.shape)\n",
    "p = pd.DataFrame(p) #* d.max(axis = 0).reset_index(drop = True)\n",
    "print(p.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valid_d.describe())\n",
    "print(train_d.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_d.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = model.predict(df)\n",
    "pd.DataFrame(p2).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "plt.axis([1e-8, 1e-1, 130000, 170000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(d.columns.values == \"MSFT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[:, 2572].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.tickers[0].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = yf.Tickers(' '.join(list(tickers.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = t.history(period=\"9y\", interval = '1d')\n",
    "?Tickers.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf.Tickers.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.history(period=\"9y\", interval = '1d', 'Open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
